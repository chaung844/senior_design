The aim of this project is to improve the way student can review course material and lecture. In many cases, student might want to record the lecture for future reference or review, however, navigating the audio recording is difficult and inefficient. Our project aims to create an application that transforms these raw recordings into structured, searchable lecture resources. Specifically, the system will perform audio segmentation to isolate the professor’s voice, generate accurate transcripts using speech-to-text model, and build a knowledge base that supports chatbot-style interaction with the lecture content. From my perspective, this project represents an intersection of artificial intelligence, natural language processing, and software development—fields I have been preparing to enter throughout my academic years.

My coursework has provided me with the technical foundation necessary to contribute to this project. In **Software Eng**, I gained valuable knowledge on project management. This will be extremely important in making sure project tasks are manageable and get done within project timeline. For managing huge database of audio files and building knowledge base, **Database Mgmt** will help me to build a well structured and efficient database. As for system design, **Deep Learning** and **Intelligent Data Analysis** are course that I'm taking to better prepare myself for finetuning audio segmentation model or speech to text model, which are core to our project.

My co-op experiences have further prepared me for the challenges of this project by allowing me to apply classroom knowledge in real-world settings. Having three semesters at Medpace as a **software development intern**, I learned how to collaborate within a large development team and gained practical skills in building and maintaining scalable applications. These roles also developed my non-technical skills, including communication, project management, and adapting to fast-changing priorities. I believe these experiences will help me not only to develop application but also to ensure our team stays aligned and productive throughout the project.

I am motivated to work on this project because I know firsthand how frustrating it can be to rely on incomplete lecture notes and navigating a long lecture audio recording. As a student, there are times when I missed an important professor note  in class and struggled to find that moment later in a recording. Creating a tool that makes lecture audio more accessible, searchable, and useful would solve a problem that many students face. Beside that, I am especially excited about the potential of integrating LLMs to build a chatbot capable of answering questions from lecture material, because it represents a step toward a more personalized, on-demand academic support. As a result, the chance to apply the technical skill i learnt and the potential of solving a problem many students face are strong source of motivations for me in this project.

My approach to this project begins with identifying the right models for audio diarization and speech recognition (speech-to-text), followed by building the pipeline for storage and retrieval of transcription data. From there, we plan to implement a retrieval-augmented generation (RAG) or agent workflow that powers the chatbot interface. The expected result is a prototype app that can process lecture recordings, generate accurate transcripts, and allow students to interact with the content more effectively than with plain audio. I will evaluate my contributions based on whether the features I develop work reliably, integrate seamlessly with the team’s codebase, and provide measurable value to the end user. In short, an end goal of this project is to help students find and understand lecture material faster and more effectively than before.