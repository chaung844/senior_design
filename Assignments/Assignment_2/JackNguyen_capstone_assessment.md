For my senior design project, my team and I are developing a system that combines speaker diarization, speech-to-text transcription, and knowledge-based agent assistance to process lecture audio files. From my academic perspective, this project represents an opportunity to apply what I have learned about artificial intelligence and machine learning in a real-world context. The main goal of our system is to take raw MP3 lecture recordings, break them into segments, convert the speech into text, and then enable intelligent querying through a knowledge-based assistant. This type of work bridges multiple areas of computer science, including audio signal processing, deep learning, and applied software engineering. The project is both technically challenging and meaningful, and it reflects what I have learned throughout college.

My college coursework has given me a strong foundation for approaching this project, especially courses that focus on artificial intelligence and data processing. The Deep Learning class with professor Gowtham Atluri exposed me to the design and implementation of neural network models, which I believe will come in handy when working on this project, especially for data preprocessing and converting speech-to-text. Other classes here at UC also provided me with problem-solving skills that help in optimizing the efficiency of our model training and data parsing. Through these courses, I have not only gained technical expertise but also developed discipline in approaching large-scale, multi-phase problems. Though I am sure I missed some specific classes, I have no doubt that all the skills I developed here at UC will prove to be useful when developing this project.

My co-op experiences have further prepared me to contribute effectively to this project by giving me hands-on experience with AI, data processing, and software development. At iCode Edu, I worked as a Game Development tutor, where I taught kids how to create a simple runner game in Unity. This helped me develop communication skills, patience, and the ability to break down complex problems into teachable steps. I also had the opportunity to train an AI model to play and eventually win the game of Pong at Discovery Lab Global, which taught me about reinforcement learning and iterative model improvement. At another co-op at UNIT Technology in Vietnam, I worked with a team to transform raw data into structured formats to support an AI model for optical character recognition (OCR). This role helped me strengthen my data cleaning and preprocessing skills, which culminated into a model capable of reading handwritten text and formatting them into Markdown and JSON. Across all of these experiences, I learned both technical skills, such as game development and AI model training, and non-technical skills, such as teamwork and adaptability. These lessons directly translate into the collaborative and technical demands of our senior design project.

I am highly motivated to work on this project because it combines my interests in artificial intelligence, human-computer interaction, and accessibility in education. To me personally, watching a recording of a lecture will never compare to being there in the lecture itself - I get distracted very easily, and also the process just doesn’t feel as rewarding as going to class. That’s why I am very interested in what we’re doing here, because it will improve the learning experience people like me could get from a recorded lecture. Having already built AI models in class and in co-op settings, I see this project as the next logical step in applying my skills to something with a specific goal in mind. I am also motivated by the challenge of integrating multiple complex systems that I have never used before—diarization, transcription, and knowledge-based agents—into one cohesive pipeline. This project gives me the chance to push myself both technically and creatively. Ultimately, my motivation comes from the belief that this work has real-world value and the potential to make information more accessible to students such as myself.

I believe that our preliminary approach to the project involves dividing the work into three main stages: first, segmenting the MP3 audio files using a speaker diarization model; second, converting the audio into text files; and third, integrating a knowledge-based agent that allows users to query the transcripts for specific topics or answers. I plan to contribute by applying my deep learning background to model training and by using my data processing experience to clean and structure outputs effectively. I expect that our results will include a working prototype capable of taking a raw lecture file and outputting both a transcript and an intelligent query system. I’m not sure about what my team will be evaluating, but my plan is to evaluate our system by measuring the accuracy of the speech-to-text component, the quality of the diarization, and the usability of the knowledge-based agent. I will know I have done a good job when our system performs reliably on real-world lecture audio and when my teammates and I can confidently present it as a functional, user-friendly tool.
